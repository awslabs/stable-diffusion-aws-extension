FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.0.1-gpu-py310-cu118-ubuntu20.04-sagemaker
# FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04
# update environment
RUN apt-get update -y

# install pkg lib for proprocess in controlnet
RUN apt-get install -y pkg-config
RUN apt-get install -y libcairo2-dev

# COPY api /opt/ml/code/
COPY stable-diffusion-aws-extension/build_scripts/api /opt/ml/code/

# add accelerate
RUN mkdir -p /root/.cache/huggingface/accelerate
COPY inference/default_config.yaml /root/.cache/huggingface/accelerate/

# download s5cmd
RUN mkdir -p /opt/ml/code/tools
RUN wget https://github.com/peak/s5cmd/releases/download/v2.0.0/s5cmd_2.0.0_Linux-64bit.tar.gz -O /opt/ml/code/tools/s5cmd_2.0.0_Linux-64bit.tar.gz
RUN tar xzvf /opt/ml/code/tools/s5cmd_2.0.0_Linux-64bit.tar.gz -C /opt/ml/code/tools/

RUN pip install --upgrade pip
RUN pip install -r /opt/ml/code/requirements.txt

# RUN pip install -v -U git+https://github.com/facebookresearch/xformers.git@v0.0.20
# RUN git clone https://github.com/facebookresearch/xformers.git && cd xformers && git checkout v0.0.20 && \
# git submodule update --init --recursive && pip install -r requirements.txt && pip install -e .

RUN wget https://aws-gcr-solutions.s3.amazonaws.com/stable-diffusion-aws-extension-github-mainline/prebuild_libs/xformers/xformer_name.txt
RUN URL=$(cat xformer_name.txt) && wget $URL
RUN URL=$(cat xformer_name.txt) && decoded=$(python3 -c "import urllib.parse; print(urllib.parse.unquote('''$URL'''))") && pip install $(basename $decoded)

RUN echo "/opt/ml/code" > "/opt/conda/lib/python3.10/site-packages/packages.pth"

WORKDIR /opt/ml/code

ENV ON_DOCKER true

# install libtcmalloc to solve memory leak for multi model switch 
# https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/9323
RUN apt-get install -y libtcmalloc-minimal4
ENV LD_PRELOAD /usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4

ENTRYPOINT ["python", "/opt/ml/code/serve"]
